{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Classification - Republican Democrats - Collecting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I did in this project is to prepare in different file a list of all the Twitter accounts of congress members (House + Senate). For preparing the list I used the Data from the website http://www.tweetcongress.org/. I saved the data in two Json forms, one for each party (independent members were counts as Democrats)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I created a function using the library Twint in order to scrape all the tweets of the congress members since 1.1.2019 and store it on Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_create_df(members,name):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        for t in members:\n",
    "    \n",
    "            c = twint.Config()\n",
    "            c.Username = t\n",
    "            c.Since = \"2019-01-01\"\n",
    "            c.Store_json = True\n",
    "            c.Format = \"{username}\"\n",
    "            c.Custom[\"tweet\"] = [\"username\",\"tweet\"]\n",
    "    # Name of the directory\n",
    "            c.Output = str(name)\n",
    "            twint.run.Search(c)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    df = pd.read_json(name+'/tweets.json', lines=True)\n",
    "    df1 =  df.groupby('username')['tweet'].apply(' '.join).reset_index()\n",
    "        \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the lists with the twitter accounts and apply the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Rep.json', 'r') as f:\n",
    "        Rep = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rep = twitter_create_df(rep1,'Republican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['repdonbacon',\n",
       " 'MarkAmodeiNV2',\n",
       " 'RepChrisSmith',\n",
       " 'RepPeteKing',\n",
       " 'RepChrisCollins']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rep[125:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep1 = Rep[126:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rep_df1 = twitter_create_df(rep1,'Republican1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rebuplican1 = pd.read_json('Republican/tweets.json', lines=True)\n",
    "Republican2 = pd.read_json('Republican1/tweets.json', lines=True)\n",
    "Final_Rep = pd.concat([Rebuplican1, Republican2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m so sorry to hear this news about Rod and h...</td>\n",
       "      <td>robert_aderholt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My family and I are praying for the Bramblett ...</td>\n",
       "      <td>robert_aderholt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proudly built on American soil! ULA built  #At...</td>\n",
       "      <td>robert_aderholt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redstone Arsenal being named to the short list...</td>\n",
       "      <td>robert_aderholt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's National Travel &amp; Tourism Week and there ...</td>\n",
       "      <td>robert_aderholt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet         username\n",
       "0  I’m so sorry to hear this news about Rod and h...  robert_aderholt\n",
       "1  My family and I are praying for the Bramblett ...  robert_aderholt\n",
       "2  Proudly built on American soil! ULA built  #At...  robert_aderholt\n",
       "3  Redstone Arsenal being named to the short list...  robert_aderholt\n",
       "4  It's National Travel & Tourism Week and there ...  robert_aderholt"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Rep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Rep['Party'] = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m so sorry to hear this news about Rod and h...</td>\n",
       "      <td>robert_aderholt</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My family and I are praying for the Bramblett ...</td>\n",
       "      <td>robert_aderholt</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proudly built on American soil! ULA built  #At...</td>\n",
       "      <td>robert_aderholt</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet         username Party\n",
       "0  I’m so sorry to hear this news about Rod and h...  robert_aderholt     R\n",
       "1  My family and I are praying for the Bramblett ...  robert_aderholt     R\n",
       "2  Proudly built on American soil! ULA built  #At...  robert_aderholt     R"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Rep.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Rep.to_csv('Final_Rep.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The same process to the Democrats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dems.json', 'r') as f:\n",
    "        Dems = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_create_df(Dems,'Democrats1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Democrats = pd.read_json('Democrats/tweets.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@repjohnlewis was gracious enough to spend ti...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At 450 pages, the Mueller Report is lengthy an...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am so grateful to have Samuel, our Selma int...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anyone who knows me knows my dad was an instru...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please help me welcome our newest summer inter...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet        username Party\n",
       "0  .@repjohnlewis was gracious enough to spend ti...  repterrisewell     D\n",
       "1  At 450 pages, the Mueller Report is lengthy an...  repterrisewell     D\n",
       "2  I am so grateful to have Samuel, our Selma int...  repterrisewell     D\n",
       "3  Anyone who knows me knows my dad was an instru...  repterrisewell     D\n",
       "4  Please help me welcome our newest summer inter...  repterrisewell     D"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Democrats[\"Party\"] = 'D'\n",
    "Democrats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Democrats= Democrats[Democrats.username != \"ilhan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One word: Impeachment. https://twitter.com/abc...</td>\n",
       "      <td>ilhanmn</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Children in our country shouldn’t go into debt...</td>\n",
       "      <td>ilhanmn</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet username Party\n",
       "0  One word: Impeachment. https://twitter.com/abc...  ilhanmn     D\n",
       "1  Children in our country shouldn’t go into debt...  ilhanmn     D"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ilhan = pd.read_json('ilhanMN/tweets.json', lines=True)\n",
    "Ilhan['Party'] = 'D'\n",
    "Ilhan.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Democrats_final = pd.concat([Democrats, Ilhan], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Democrats_final.to_csv('Democrats_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating joint data file for Democrats and Republicans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Congress_tweets = pd.concat([Democrats_final, Final_Rep], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176280"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Final_Congress_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Congress_tweets.to_csv(r'Final_Congress.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@repjohnlewis was gracious enough to spend ti...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At 450 pages, the Mueller Report is lengthy an...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am so grateful to have Samuel, our Selma int...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anyone who knows me knows my dad was an instru...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please help me welcome our newest summer inter...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet        username Party\n",
       "0  .@repjohnlewis was gracious enough to spend ti...  repterrisewell     D\n",
       "1  At 450 pages, the Mueller Report is lengthy an...  repterrisewell     D\n",
       "2  I am so grateful to have Samuel, our Selma int...  repterrisewell     D\n",
       "3  Anyone who knows me knows my dad was an instru...  repterrisewell     D\n",
       "4  Please help me welcome our newest summer inter...  repterrisewell     D"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Congress_tweets  = pd.read_csv('Final_Congress.csv')\n",
    "Final_Congress_tweets.drop(['Unnamed: 0'], axis=1, inplace  = True)\n",
    "Final_Congress_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username\n",
       "pattymurray      1531\n",
       "repdmp           1362\n",
       "repjayapal       1314\n",
       "senrobportman    1274\n",
       "senwhitehouse    1261\n",
       "Name: tweet, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Congress_tweets.groupby('username')['tweet'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username\n",
       "senrobportman    1274\n",
       "senrickscott     1150\n",
       "johncornyn       1107\n",
       "senrubiopress    1026\n",
       "lisamurkowski     981\n",
       "Name: tweet, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Rep.groupby('username')['tweet'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Party\n",
       "D    112044\n",
       "R     64236\n",
       "Name: tweet, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Congress_tweets.groupby('Party')['tweet'].count().sort_values(ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Congress_tweets['tweet']  = Final_Congress_tweets['tweet'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@repjohnlewis was gracious enough to spend ti...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at 450 pages, the mueller report is lengthy an...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am so grateful to have samuel, our selma int...</td>\n",
       "      <td>repterrisewell</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet        username Party\n",
       "0  .@repjohnlewis was gracious enough to spend ti...  repterrisewell     D\n",
       "1  at 450 pages, the mueller report is lengthy an...  repterrisewell     D\n",
       "2  i am so grateful to have samuel, our selma int...  repterrisewell     D"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Congress_tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining to tweets by parties and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>.@repjohnlewis was gracious enough to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>i’m so sorry to hear this news about rod and h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Party                                              tweet\n",
       "0     D  .@repjohnlewis was gracious enough to spend ti...\n",
       "1     R  i’m so sorry to hear this news about rod and h..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parties_Tweet  =Final_Congress_tweets.groupby('Party')['tweet'].apply(' '.join).reset_index()\n",
    "\n",
    "Parties_Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "Parties_Tweet[\"tweet\"] = Parties_Tweet['tweet'].apply(lambda x: nltk.regexp_tokenize(x,pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parties_Tweet['tweet'][0] = [word for word in Parties_Tweet['tweet'][0] if word in vocab_total_D_R]\n",
    "Parties_Tweet['tweet'][1] = [word for word in Parties_Tweet['tweet'][1] if word in vocab_total_D_R] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "stopwords_list += ['0','1','2','3','4','5','6','7','8','9','com','https','www',\n",
    "                   'pic','twitter','ly','http','html','gov','cfm','utm']\n",
    "stopwords_list += list(string.ascii_lowercase)\n",
    "\n",
    "\n",
    "Parties_Tweet['tweet'][0] = [word for word in Parties_Tweet['tweet'][0] if word not in stopwords_list ] \n",
    "Parties_Tweet['tweet'][1] = [word for word in Parties_Tweet['tweet'][1] if word not in stopwords_list ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>[repjohnlewis, gracious, enough, spend, time, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>[sorry, hear, news, rod, wife, ability, radio,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Party                                              tweet\n",
       "0     D  [repjohnlewis, gracious, enough, spend, time, ...\n",
       "1     R  [sorry, hear, news, rod, wife, ability, radio,..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parties_Tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2415510 1329313\n"
     ]
    }
   ],
   "source": [
    "print (len(Parties_Tweet['tweet'][0]), len(Parties_Tweet['tweet'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122462 92327\n",
      "181194\n"
     ]
    }
   ],
   "source": [
    "vocab1 = list(set(Parties_Tweet['tweet'][0]))\n",
    "vocab2 = list(set(Parties_Tweet['tweet'][1]))\n",
    "vocab_total =list(set(vocab1+vocab2))\n",
    "print (len(vocab1), len(vocab2))\n",
    "print (len(vocab_total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngrams and word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_congress_freqdist =  nltk.FreqDist(Parties_Tweet[\"tweet\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('status', 16397),\n",
       " ('today', 15047),\n",
       " ('trump', 12286),\n",
       " ('house', 12037),\n",
       " ('people', 10355),\n",
       " ('act', 9833),\n",
       " ('congress', 9826),\n",
       " ('work', 9755),\n",
       " ('us', 9017),\n",
       " ('health', 8654),\n",
       " ('must', 8431),\n",
       " ('president', 8321),\n",
       " ('women', 7843),\n",
       " ('proud', 7806),\n",
       " ('need', 7640),\n",
       " ('time', 7601),\n",
       " ('bill', 7522),\n",
       " ('american', 7360),\n",
       " ('news', 7226),\n",
       " ('families', 7209)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing democrats most common word and their frequency\n",
    "D_congress_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_congress_freqdist =  nltk.FreqDist(Parties_Tweet[\"tweet\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('today', 8326),\n",
       " ('status', 7619),\n",
       " ('house', 6071),\n",
       " ('great', 5836),\n",
       " ('news', 5751),\n",
       " ('border', 5041),\n",
       " ('work', 4712),\n",
       " ('senate', 4458),\n",
       " ('congress', 4267),\n",
       " ('bill', 4182),\n",
       " ('us', 3981),\n",
       " ('act', 3929),\n",
       " ('thank', 3917),\n",
       " ('people', 3886),\n",
       " ('new', 3821),\n",
       " ('bit', 3711),\n",
       " ('day', 3543),\n",
       " ('time', 3535),\n",
       " ('support', 3442),\n",
       " ('state', 3439)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing Republicans most common word and their frequency\n",
    "R_congress_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_finder = BigramCollocationFinder.from_words(Parties_Tweet[\"tweet\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_scored = D_finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('health', 'care'), 0.0015831025332124478),\n",
       " (('climate', 'change'), 0.0010685114116687573),\n",
       " (('american', 'people'), 0.0009641856171160542),\n",
       " (('press', 'releases'), 0.0009203025448042028),\n",
       " (('trump', 'administration'), 0.0008855272799533017),\n",
       " (('president', 'trump'), 0.0008420581988896755),\n",
       " (('gun', 'violence'), 0.0008308804351876001),\n",
       " (('house', 'media'), 0.0006354765660253943),\n",
       " (('across', 'country'), 0.0006106370911318935),\n",
       " (('make', 'sure'), 0.0005882815637277428),\n",
       " (('pre', 'existing'), 0.0005675820013164921),\n",
       " (('federal', 'workers'), 0.0005398445876854163),\n",
       " (('town', 'hall'), 0.000527838841486891),\n",
       " (('look', 'forward'), 0.0005034133578416153),\n",
       " (('government', 'shutdown'), 0.00049554752412534),\n",
       " (('existing', 'conditions'), 0.00048519774291971466),\n",
       " (('every', 'day'), 0.0004740199792176393),\n",
       " (('united', 'states'), 0.00046118625052266396),\n",
       " (('years', 'ago'), 0.0004537344080546137),\n",
       " (('high', 'school'), 0.00043469081063626314)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing democrats most common bi-grams words and their ratio to total \n",
    "D_scored[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_finder = BigramCollocationFinder.from_words(Parties_Tweet[\"tweet\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('press', 'releases'), 0.001300671850798119),\n",
       " (('border', 'security'), 0.0008297519094449539),\n",
       " (('senate', 'public'), 0.0008169633487372801),\n",
       " (('public', 'index'), 0.0008026702514757623),\n",
       " (('look', 'forward'), 0.0007846158128296346),\n",
       " (('house', 'media'), 0.0007229298141220315),\n",
       " (('southern', 'border'), 0.0007011140340912938),\n",
       " (('health', 'care'), 0.0006777937175067121),\n",
       " (('men', 'women'), 0.0006740323761221022),\n",
       " (('united', 'states'), 0.0006612438154144283),\n",
       " (('american', 'people'), 0.0006130986456914211),\n",
       " (('law', 'enforcement'), 0.0005973010118760593),\n",
       " (('high', 'school'), 0.0005784943049530096),\n",
       " (('president', 'trump'), 0.0005724761587376336),\n",
       " (('looking', 'forward'), 0.000479194892399307),\n",
       " (('last', 'week'), 0.00047016767307624314),\n",
       " (('national', 'security'), 0.0004664063316916332),\n",
       " (('youtube', 'watch'), 0.00045211323443011543),\n",
       " (('news', 'local'), 0.0004265361130147678),\n",
       " (('media', 'center'), 0.00040321579643018613)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing Republican most common bi-grams words and their ratio to total \n",
    "R_scored = R_finder.score_ngrams(bigram_measures.raw_freq)\n",
    "R_scored[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dgram3 = ngrams(Parties_Tweet[\"tweet\"][0], 3)\n",
    "Rgram3 = ngrams(Parties_Tweet[\"tweet\"][1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dn3 = nltk.FreqDist(Dgram3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('pre', 'existing', 'conditions'), 1172),\n",
       " (('media', 'press', 'releases'), 842),\n",
       " (('house', 'media', 'press'), 840),\n",
       " (('house', 'media', 'center'), 687),\n",
       " (('media', 'center', 'press'), 643),\n",
       " (('center', 'press', 'releases'), 643),\n",
       " (('nytimes', 'us', 'politics'), 619),\n",
       " (('congressional', 'art', 'competition'), 419),\n",
       " (('affordable', 'care', 'act'), 375),\n",
       " (('american', 'people', 'deserve'), 373)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing democrats most common tri-grams words and their total count \n",
    "Dn3.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rn3 = nltk.FreqDist(Rgram3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('senate', 'public', 'index'), 1066),\n",
       " (('house', 'media', 'center'), 499),\n",
       " (('media', 'center', 'press'), 487),\n",
       " (('center', 'press', 'releases'), 487),\n",
       " (('source', 'ig', 'share'), 434),\n",
       " (('ig', 'share', 'igshid'), 432),\n",
       " (('media', 'press', 'releases'), 432),\n",
       " (('documentsingle', 'aspx', 'documentid'), 428),\n",
       " (('house', 'media', 'press'), 422),\n",
       " (('house', 'news', 'documentsingle'), 402)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing Republicans most common tri-grams words and their total count \n",
    "Rn3.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dgram4 = ngrams(Parties_Tweet[\"tweet\"][0], 4)\n",
    "Rgram4 = ngrams(Parties_Tweet[\"tweet\"][1], 4)\n",
    "Dn4 = nltk.FreqDist(Dgram4)\n",
    "Rn4 = nltk.FreqDist(Rgram4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('house', 'media', 'press', 'releases'), 840),\n",
       " (('house', 'media', 'center', 'press'), 643),\n",
       " (('media', 'center', 'press', 'releases'), 643),\n",
       " (('people', 'pre', 'existing', 'conditions'), 322),\n",
       " (('house', 'news', 'documentsingle', 'aspx'), 317),\n",
       " (('news', 'documentsingle', 'aspx', 'documentid'), 316),\n",
       " (('martin', 'luther', 'king', 'jr'), 268),\n",
       " (('senate', 'news', 'press', 'releases'), 245),\n",
       " (('americans', 'pre', 'existing', 'conditions'), 240),\n",
       " (('equal', 'pay', 'equal', 'work'), 211)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing Democrats most common four-grams words and their total count\n",
    "Dn4.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('media', 'center', 'press', 'releases'), 487),\n",
       " (('house', 'media', 'center', 'press'), 454),\n",
       " (('source', 'ig', 'share', 'igshid'), 432),\n",
       " (('house', 'media', 'press', 'releases'), 421),\n",
       " (('house', 'news', 'documentsingle', 'aspx'), 402),\n",
       " (('news', 'documentsingle', 'aspx', 'documentid'), 400),\n",
       " (('index', 'press', 'releases', 'id'), 371),\n",
       " (('senate', 'public', 'index', 'press'), 370),\n",
       " (('public', 'index', 'press', 'releases'), 370),\n",
       " (('born', 'alive', 'abortion', 'survivors'), 232)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing Republicans most common four-grams words and their total count \n",
    "Rn4.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dgram5 = ngrams(Parties_Tweet[\"tweet\"][0], 5)\n",
    "Rgram5 = ngrams(Parties_Tweet[\"tweet\"][1], 5)\n",
    "Dn5 = nltk.FreqDist(Dgram5)\n",
    "Rn5 = nltk.FreqDist(Rgram5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('house', 'media', 'center', 'press', 'releases'), 643),\n",
       " (('house', 'news', 'documentsingle', 'aspx', 'documentid'), 316),\n",
       " (('dr', 'martin', 'luther', 'king', 'jr'), 176),\n",
       " (('house', 'media', 'press', 'releases', 'rep'), 165),\n",
       " (('duckworth', 'senate', 'news', 'press', 'releases'), 124),\n",
       " (('murphy', 'senate', 'newsroom', 'press', 'releases'), 116),\n",
       " (('click', 'module', 'top', 'stories', 'pgtype'), 112),\n",
       " (('module', 'top', 'stories', 'pgtype', 'homepage'), 112),\n",
       " (('action', 'click', 'module', 'top', 'stories'), 111),\n",
       " (('media', 'center', 'press', 'releases', 'congressman'), 110)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing Democrats most common five-grams words and their total count\n",
    "Dn5.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('house', 'media', 'center', 'press', 'releases'), 454),\n",
       " (('house', 'news', 'documentsingle', 'aspx', 'documentid'), 400),\n",
       " (('senate', 'public', 'index', 'press', 'releases'), 370),\n",
       " (('public', 'index', 'press', 'releases', 'id'), 366),\n",
       " (('born', 'alive', 'abortion', 'survivors', 'protection'), 222),\n",
       " (('alive', 'abortion', 'survivors', 'protection', 'act'), 221),\n",
       " (('rubio', 'senate', 'public', 'index', 'press'), 220),\n",
       " (('senate', 'public', 'index', 'pressreleases', 'id'), 122),\n",
       " (('young', 'senate', 'newsroom', 'press', 'releases'), 104),\n",
       " (('wicker', 'senate', 'public', 'index', 'wicker'), 103)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing Republicans most common five-grams words and their total count \n",
    "Rn5.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parties_Tweet['tweet'][0] = [porter.stem(word) for word in Parties_Tweet['tweet'][0]]\n",
    "Parties_Tweet['tweet'][1] = [porter.stem(word) for word in Parties_Tweet['tweet'][1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108551 80894\n",
      "163668\n"
     ]
    }
   ],
   "source": [
    "#checking the size of new vocabulry after stemming\n",
    "vocab5 = list(set(Parties_Tweet['tweet'][0]))\n",
    "vocab6 = list(set(Parties_Tweet['tweet'][1]))\n",
    "vocab_total_after_stem =list(set(vocab5+vocab6))\n",
    "print (len(vocab5), len(vocab6))\n",
    "print (len(vocab_total_after_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheking frequency of words\n",
    "D_stem_count = nltk.FreqDist(Parties_Tweet[\"tweet\"][0])\n",
    "R_stem_count = nltk.FreqDist(Parties_Tweet[\"tweet\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plumber', 3),\n",
       " ('ggi', 3),\n",
       " ('emce', 3),\n",
       " ('wink', 3),\n",
       " ('maryam', 3),\n",
       " ('fop', 3),\n",
       " ('wss', 3),\n",
       " ('incomprehens', 3),\n",
       " ('rusi', 3),\n",
       " ('fcdb', 3)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can see that most of the words are in very low frequency\n",
    "D_stem_count.most_common()[20000:20010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_stem_count.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of final features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I would like to have no more than 10,000 features in my model,\n",
    "#so I chose only words which appears more than 14 times in the entire corpus\n",
    "Final_vocab_D = [word for word, freq in D_stem_count.items() if freq>=15] \n",
    "Final_vocab_R = [word for word, freq in R_stem_count.items() if freq>=15] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9639"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_total_D_R =list(set(Final_vocab_D + Final_vocab_R))\n",
    "len(vocab_total_D_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the final list to json file\n",
    "with open('vocab_total_D_R.json', 'w') as outfile:\n",
    "     json.dump(vocab_total_D_R, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
