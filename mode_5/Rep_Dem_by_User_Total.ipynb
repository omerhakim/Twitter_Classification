{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Republican  = pd.read_csv('joint_republican.csv')\n",
    "Republican.drop(['Unnamed: 0'], axis=1, inplace  = True)\n",
    "Democrats  = pd.read_csv('joint_democrats.csv')\n",
    "Democrats.drop(['Unnamed: 0'], axis=1, inplace  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_RD_Tweet_User = pd.concat([Democrats, Republican], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_RD_Tweet_User.to_csv('Final_RD_Tweet_User.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benniegthompson</td>\n",
       "      <td>['today', 'rememb', 'reflect', 'life', 'civil'...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bettymccollum04</td>\n",
       "      <td>['state', 'foreign', 'oper', 'appropsdem', 'bi...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>billpascrell</td>\n",
       "      <td>[\"nation'\", 'firefight', 'put', 'live', 'line'...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                                              tweet Target\n",
       "0  benniegthompson  ['today', 'rememb', 'reflect', 'life', 'civil'...      D\n",
       "1  bettymccollum04  ['state', 'foreign', 'oper', 'appropsdem', 'bi...      D\n",
       "2     billpascrell  [\"nation'\", 'firefight', 'put', 'live', 'line'...      D"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_RD_Tweet_User.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_RD_Tweet_User.set_index('username', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']= 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Final_RD_Tweet_User['tweet']\n",
    "target = Final_RD_Tweet_User['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data , target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_data_train = vectorizer.fit_transform(X_train)\n",
    "tf_idf_data_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406, 9516)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier( verbose=1,n_jobs=-1)\n",
    "xgb_classifier = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(tf_idf_data_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_data_train)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9064 \t\t Testing Accuracy: 0.7353\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "nb_train_score = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_score = accuracy_score(y_test, nb_test_preds)\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))\n",
    "print(\"\")\n",
    "print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  2],\n",
       "       [25, 25]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test, nb_test_preds, labels = ['D','R'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_classifier.fit(tf_idf_data_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_data_train)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Training Accuracy: 0.9926 \t\t Testing Accuracy: 0.9314\n"
     ]
    }
   ],
   "source": [
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48,  4],\n",
       "       [ 3, 47]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test, rf_test_preds, labels = ['D','R'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding where the mistake was"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier.fit(tf_idf_data_train, y_train)\n",
    "xgb_train_preds = xgb_classifier.predict(tf_idf_data_train)\n",
    "xgb_test_preds = xgb_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost\n",
      "Training Accuracy: 1.0 \t\t Testing Accuracy: 0.9706\n"
     ]
    }
   ],
   "source": [
    "xgb_train_score = accuracy_score(y_train, xgb_train_preds)\n",
    "xgb_test_score = accuracy_score(y_test, xgb_test_preds)\n",
    "print('xgboost')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(xgb_train_score, xgb_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  2],\n",
       "       [ 1, 49]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test, xgb_test_preds, labels = ['D','R'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_data_train = count_vectorizer.fit_transform(X_train)\n",
    "count_data_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406, 9516)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Baise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(count_data_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(count_data_train)\n",
    "nb_test_preds = nb_classifier.predict(count_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB\n",
      "Training Accuracy: 0.9951 \t\t Testing Accuracy: 0.9608\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "nb_train_score = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_score = accuracy_score(y_test, nb_test_preds)\n",
    "print (\"NB\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))\n",
    "print(\"\")\n",
    "print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48,  4],\n",
       "       [ 0, 50]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test, nb_test_preds, labels = ['D','R'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_classifier.fit(count_data_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(count_data_train)\n",
    "rf_test_preds = rf_classifier.predict(count_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Training Accuracy: 1.0 \t\t Testing Accuracy: 0.9118\n"
     ]
    }
   ],
   "source": [
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  2],\n",
       "       [ 7, 43]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test, rf_test_preds, labels = ['D','R'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier.fit(count_data_train, y_train)\n",
    "xgb_train_preds = xgb_classifier.predict(count_data_train)\n",
    "xgb_test_preds = xgb_classifier.predict(count_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost\n",
      "Training Accuracy: 1.0 \t\t Testing Accuracy: 0.951\n"
     ]
    }
   ],
   "source": [
    "xgb_train_score = accuracy_score(y_train, xgb_train_preds)\n",
    "xgb_test_score = accuracy_score(y_test, xgb_test_preds)\n",
    "print('xgboost')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(xgb_train_score, xgb_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  3],\n",
       "       [ 2, 48]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test, xgb_test_preds, labels = ['D','R'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRED\n",
       "0    R\n",
       "1    R\n",
       "2    R\n",
       "3    D\n",
       "4    D"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame(y_test)\n",
    "df6 = pd.DataFrame(xgb_test_preds, columns = ['PRED'])\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['PRED'] = df6['PRED'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repjoshharder D\n",
      "repvisclosky D\n",
      "repbenmcadams D\n",
      "repjohncurtis R\n",
      "susanwbrooks R\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df5)):\n",
    "    if df5.Target[i] != df5.PRED[i]:\n",
    "        print (df5.username[i],df5.Target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>worker</th>\n",
       "      <td>0.060827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equalityact</th>\n",
       "      <td>0.043796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trumpshutdown</th>\n",
       "      <td>0.036496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climat</th>\n",
       "      <td>0.026764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.024331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>due</th>\n",
       "      <td>0.024331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forthepeopl</th>\n",
       "      <td>0.021898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.021898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitehous</th>\n",
       "      <td>0.019465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.019465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun</th>\n",
       "      <td>0.019465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal</th>\n",
       "      <td>0.019465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbtq</th>\n",
       "      <td>0.019465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abort</th>\n",
       "      <td>0.017032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aca</th>\n",
       "      <td>0.017032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lowest</th>\n",
       "      <td>0.017032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potu</th>\n",
       "      <td>0.017032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>0.017032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equalpay</th>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equalpayday</th>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violenc</th>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protectourcar</th>\n",
       "      <td>0.014599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discrimin</th>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unborn</th>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aliv</th>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc</th>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dreamer</th>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blackhistorymonth</th>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay</th>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newborn</th>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evil</th>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glad</th>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liber</th>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illeg</th>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobsreport</th>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bless</th>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foxbusi</th>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>further</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vawa</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>born</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natur</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abid</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paycheckfairnessact</th>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paycheck</th>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suppos</th>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honor</th>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "worker                 0.060827\n",
       "equalityact            0.043796\n",
       "trumpshutdown          0.036496\n",
       "climat                 0.026764\n",
       "news                   0.024331\n",
       "due                    0.024331\n",
       "forthepeopl            0.021898\n",
       "life                   0.021898\n",
       "whitehous              0.019465\n",
       "gender                 0.019465\n",
       "gun                    0.019465\n",
       "equal                  0.019465\n",
       "lgbtq                  0.019465\n",
       "abort                  0.017032\n",
       "aca                    0.017032\n",
       "lowest                 0.017032\n",
       "potu                   0.017032\n",
       "wall                   0.017032\n",
       "equalpay               0.014599\n",
       "equalpayday            0.014599\n",
       "violenc                0.014599\n",
       "protectourcar          0.014599\n",
       "discrimin              0.012165\n",
       "unborn                 0.012165\n",
       "aliv                   0.012165\n",
       "sinc                   0.012165\n",
       "dreamer                0.012165\n",
       "blackhistorymonth      0.012165\n",
       "pay                    0.012165\n",
       "newborn                0.009732\n",
       "evil                   0.009732\n",
       "glad                   0.009732\n",
       "liber                  0.009732\n",
       "illeg                  0.009732\n",
       "jobsreport             0.009732\n",
       "bless                  0.009732\n",
       "foxbusi                0.009732\n",
       "send                   0.007299\n",
       "thank                  0.007299\n",
       "further                0.007299\n",
       "pre                    0.007299\n",
       "vawa                   0.007299\n",
       "born                   0.007299\n",
       "natur                  0.007299\n",
       "abid                   0.007299\n",
       "paycheckfairnessact    0.007299\n",
       "paycheck               0.004866\n",
       "wa                     0.004866\n",
       "suppos                 0.004866\n",
       "honor                  0.004866"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = pd.DataFrame(count_data_train.todense(),columns = count_vectorizer.get_feature_names())\n",
    "feature_importance = pd.DataFrame(xgb_classifier.feature_importances_, index=df_count.columns, columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importance.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(xgb_classifier.feature_importances_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "columns not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-d5e5731aa7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: columns not found"
     ]
    }
   ],
   "source": [
    "for index in sorted_idx:\n",
    "    print([count_data_train.columns[index], xgb_classifier.feature_importances_[index]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
